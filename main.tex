\documentclass[11pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amssymb,amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{tikz}
\usetikzlibrary{automata,positioning,calc,shapes,arrows}
\usepackage{multirow}
\usepackage{caption}
\captionsetup[figure]{font=small,labelfont=small}
\usepackage[english]{babel} 
\usepackage{float}
\linespread{1.2} 
\usepackage[left=2.5cm,right=2.5cm,bottom=2cm,top=2cm,includeheadfoot]{geometry}
\title{Automata \& Queueing Systems}
\author{Francesco Casciola}
\begin{document}
\maketitle

\section{Introduction and State Automata}

A system with time-driven dynamics is a kind of system in which, even though events might occur, after that the system doesn’t stay in the same state, but this variates as the time goes on.

\bigskip
\noindent
A system with event-driven dynamics is a kind of system whose state variates only with the occurrence of certain events and it is constant in the time between an event and the next one. This produces a piecewise constant function in the time.


\paragraph{Discrete Event System} Dynamical system with discrete states and event-driven dynamics. 
\paragraph{State Automaton} It’s a model through which Discrete Event Systems can be represented and it’s identified as a $5-$tuple $(\mathcal{E},\mathcal{X},\Gamma,f,x_0)$ where:
\begin{itemize}
\item $\mathcal{E}$ is a discrete set of events.
\item $\mathcal{X}$ is a discrete set of states.
\item $\Gamma$ is a function taking values $\mathcal{X}\rightarrow 2^\mathcal{E}$, where $2^\mathcal{E}$ is the `power set’ of the set $\mathcal{E}$ and it represents the set of all the possible subsets of $\mathcal{E}$:
\begin{equation}
\text{e.g. : }\mathcal{E}={a,b} \Rightarrow 2^\mathcal{E}=\{\emptyset, (a), (b), (a,b,)\} \text{\hspace{1 cm};\hspace{1 cm}} dim(2^\mathcal{E}) = 2^{dim(\mathcal{E})}
\nonumber
\end{equation}
$\Gamma(x)$ represents the set of the events that are possible in the state $x$. 
\item $f$ is a function taking values in $\mathcal{X}\times\mathcal{E}\rightarrow\mathcal{X}$ and defines the state transitions, such that $x' = f(x,e)$ is the next state when event $e\in\Gamma(x)$ occurs in the current state $x\in\mathcal{X}$.
\item $x_0\in\mathcal{X}$ is the initial state.
\end{itemize}
It’s fundamental to not to confuse the model with the actual system since the models always introduce a certain level of approximation with respect to the reality. 
\newpage
\paragraph{The concept of feasibility} When thinking about a real system there are many events that are possible and many others that aren’t. When modelling a system, the events that are extremely improbable (at a level that they can be considered impossible) must be excluded, but there are some events that are state-related that are actually impossible. For instance, a machine which is not working cannot complete a job. A sequence of events $(e_1,e_2,\dots,e_n)$ is feasible (could occur in reality) only if all the events of the sequence occur in states in which they are possible:
\begin{equation}
(e_1,e_2,\dots,e_n ) \hspace{0.5cm} \text{is feasible if: } e_k \in \Gamma (x_{k-1}) \hspace{0.5cm} , \hspace{0.5cm} k\in (1,2,\dots,n) \hspace{0.5cm} , \hspace{0.5cm} x_k=f(x_{k-1},e_k )
\nonumber
\end{equation}
The problem is that the unfeasible sequences aren’t always obvious, which means that to find some of them it’s either necessary to have a deep knowledge of the system or to run a big amount of simulations of the model (assuming that it’s realistic enough) in order to find sequences causing errors.

\paragraph{State Automaton with outputs} It’s a model through which Discrete Event Systems can be represented and it’s identified as a $5-$tuple $(\mathcal{E},\mathcal{X},\Gamma,f,x_0,\mathcal{Y},g)$ where:
\begin{itemize}
\item $(\mathcal{E},\mathcal{X},\Gamma,f,x_0)$ is a state automaton.
\item $\mathcal{Y}$ is a discrete set of outputs.
\item $g$ is a function taking values in $\mathcal{X}\rightarrow\mathcal{Y}$ and defines the output, such that $y=g(x)$, where $x\in\mathcal{X}$ is the current state and $y\in\mathcal{Y}$ is the current output.
\end{itemize}

\section{Timed Automata}
\paragraph{Concept of time in DES} In a real system, when an event occurs, it’s also possible to know the time in which this happens. When trying to introduce the concept of time in a State Automaton model, it’s important to keep a concept in mind:
\begin{itemize}
\item Time cannot be given as an input to the state automaton, since the inputs are independent of the system while the time instants in which events occur depend on the system itself. 
\end{itemize}
This can be demonstrated by considering the execution of the jobs on certain elements by a given machine as regulated by two different disciplines (while having the time as input): First-In-First-Out (FIFO) and Round-Robin (RR). The FIFO discipline is self-explanatory. The RR is based on the concept of `time slice’, which is the maximum time the machine dedicates to a certain element that needs processing before switching to the next one. In the case in which the time needed to complete the job on the first element is higher than the time slice, the partially processed element will be put back in the queue in last position.
Both the disciplines allow the machine to complete the job on all the elements, but, even if their times of arrival are the same, the times in which they are accepted in the system and the ones in which the processing on every single element terminates are different. This means that the time instants in which the events occur cannot be given as input to the system, as they depend on it.
\newpage
\paragraph{Timed Automaton}
A solution to the problem presented in the past paragraph is to use as inputs, instead of the time instants, the duration of processes, at the end of which the events occur. This way, when the system enters a state x in which a given event e is possible, in the model it’s possible to start a process of a set duration. This process represents the `lifetime of the event’ and when the lifetime finishes, the event will occur. Finally, the time in which the event e occurs is obtained as sum of the time instants in which the system enters the state x and the lifetime of the event e.
This allows us to define the timed automaton as a $6-$tuple $(\mathcal{E},\mathcal{X},\Gamma,f,x_0,V)$, where: 
\begin{itemize}
\item $(\mathcal{E},\mathcal{X},\Gamma,f,x_0)$ is a state automaton. 
\item $V$ is the `clock structure’ which is an array of `clock sequences’ of the various events:
\begin{equation}
V=\{V_e ;e\in\mathcal{E}\}\hspace{0.5cm};\hspace{0.5cm}V_e=\{V_{e1}, V_{e2}, V_{e3},\dots\}
\nonumber
\end{equation}
\end{itemize}	
\noindent
Where $V_e$ is the clock sequence of the event e and $V_{ei}$ is the lifetime of the $i-$th occurrence of the event $e$. It’s important to keep in mind that the lifetimes must be always positive for the model to be representative of a real system.

\paragraph{Residual Times} According to the definition of a Timed Automaton when entering a state in which an event is possible a process with a certain lifetime starts. Let’s consider the situation in which there are two lifetimes, related to two events $e_1$ and $e_2$, where $V_{e1}<V_{e2}$ that start when the system enters the state $x_{k-1}$. The event $e_1$ will occur first and the system will enter state $x_k$. If event $e_2$ is still possible in state $x_k$ then, instead of starting a new process with its lifetime, the `residual lifetime’ $y_{e2}=V_{e2}-V_{e1}$ is employed. If event $e_2$ is not possible there are two options: either dropping the current lifetime in order to start a new process when the event becomes possible again or keeping the residual lifetime in order to reuse it when the system enters a state in which $e_2$ is possible again. The choice between these options, in the model, depends on the behaviour of the system.

\newpage 

\paragraph{Notation for Timed Automata}
The `score’ of an event $e$ at the time $t$, denoted $n_e (t)$, is the number of lifetimes of the event e completed in the interval $[t_0,t]$. From now on the following notation will be used:
\begin{itemize}
\item With respect to event occurrences:
	\begin{itemize}
	\item $k$ is the event index $(k=1,2,3,\dots)$.
	\item $e_k$ is the $k-$th event.
	\item $x_k$ is the state reached after $e_k$ occurs.
	\item $t_k$ is the time when the $e_k$ occurs.
	\item $n_{e,k}$ is score of the event $e$ after the $k-$th event.
	\item $y_{e,k}$ is the residual lifetime of $e$ after the $k-$th event.
	\end{itemize} 
\item With respect to time:
	\begin{itemize}
	\item $t$ is the continuous time.
	\item $n_{e}(t)$ is score of the event $e$ after the time $t$.
	\item $x(t)$ is the state of the system at time $t$.
	\end{itemize} 
\end{itemize}
\paragraph{General algorithm for event timing} Before explaining the algorithm it’s important to know that it’s possible to use it only when the following assumptions stand:
\begin{enumerate}
\item When an event $e$ doesn’t occur and it’s not possible in the next state, its residual lifetime is ignored, and a new lifetime is taken from the corresponding clock sequence.
\item When event $e$ occurs, the next time it becomes possible a new total lifetime is taken from the corresponding clock sequence.
\item If the event $e$ doesn’t occur and it’s still possible in the next state, then its residual lifetime is employed.
\end{enumerate}
 
\newpage
\noindent
Under these assumptions, the algorithm is composed by the following steps:
\begin{enumerate}
\setcounter{enumi}{-1}
\item \textbf{Initialization: }	for all the events $e\in\mathcal{E}$, if $e\in\Gamma(x_0)$ we consider $y_{e,0}=V_{e1}$ and $n_{e,0}=1$. Otherwise, if $e\notin\Gamma(x_0)$, $y_{e,0}$ is undefined and $n_{e,0}=0$.
\item \textbf{Selection of the next event: } the next event is the one with the smallest residual lifetime:
\begin{equation}
e_k = \argmin\limits_{e\in\Gamma(x_{k-1})} (y_{e,k-1}) = \text{arg} (y_{k-1}^*)
\nonumber
\end{equation}
\item \textbf{Determination of the time instant of the next event}
\begin{equation}
t_k=t_{k-1}+y_{k-1}^*
\nonumber
\end{equation}
\item \textbf{State update}
\begin{equation}
x_{k}=f(x_{k-1},e_{k})
\nonumber
\end{equation}
\item \textbf{Score update}
\begin{equation}
n_{e,k}=
\begin{cases}
n_{e,k} = n_{e,k-1} & \text{if a residual lifetime is used} \\
n_{e,k} = n_{e,k-1}+1 & \text{if a new total lifetime is used} \\
\end{cases}
\nonumber
\end{equation}
\item \textbf{Update of the residual lifetimes}
\begin{equation}
y_{e,k}=
\begin{cases}
V_{e,n_{e,k}} & \text{if } \left[\left(e\notin\Gamma(x_{k-1})\wedge e\in\Gamma(x_{k})\right)\vee\left(e=e_{k} \wedge e\in \Gamma(x_{k})\right)\right] \\
y_{e,k-1}-y_{k-1}^{*} & \text{if } \left[e\in\Gamma(x_{k-1})\wedge e\neq e_{k} \wedge e\in\Gamma(x_{k}) \right] \\
\end{cases}
\nonumber
\end{equation}
\item \textbf{Assign value $k+1$ to variable $k$ and restart from step $1$.}
\end{enumerate}
\newpage
\section{Stochastic State Automata}
\paragraph{Concept of ubiquitous uncertainty}
Often there are some levels of uncertainty in the systems that need to be also inserted in the models. An example would be the one of a system with two machines which operate in parallel: how do we know, if they are both available, which one will start working when a piece arrives? Here’s a list of the elements in the Timed automaton which are subject to uncertainty:
\begin{itemize}
\item $f$: The example just described is a case of uncertainty in the state transition function.
\item $x_0$: Let’s consider a shop, if it opens at a given time $t_0$ and there are some people waiting for it to open, how long is the queue (state) at $t_0$? 
\item $V$: The processing times can vary depending on the request, it’s not always possible to know them in advance.
\end{itemize}
The need to introduce elements of uncertainty in the model bring to the definition of the next kind of state automaton.
\paragraph{Stochastic State Automaton}
It’s a model through which Discrete Event Systems with elements of uncertainty can be represented and it’s identified as a $6$-tuple $(\mathcal{E},\mathcal{X},\Gamma,P,p_0,F)$ where:
\begin{itemize}
\item $(\mathcal{E},\mathcal{X},\Gamma)$ are the same as for the timed automaton.
\item $P$ is a set of transition probabilities from a state to another. It substitutes $f$ and it’s defined as follows:
\begin{equation}
\begin{matrix}
P(x'|x,e)=P(\mathcal{X}_{k+1}=x' \hspace{4pt}|\hspace{4pt} \mathcal{X}_k=x ; \mathcal{E}_(k+1)=e )&&,&&\forall x,x'\in\mathcal{X} &&,&& \forall \mathcal{E}\in \Gamma(x) 
\end{matrix}
\nonumber
\end{equation} 
This set of probabilities generalises the deterministic case, in fact if we have:
\begin{equation}
\begin{matrix}
x'=f(x,e)&&\Rightarrow && P(x'\hspace{5pt}|\hspace{5pt}x,e)=1
\end{matrix}
\nonumber
\end{equation}
\item $p_0$ is a discrete random variable which defines the initial state probabilities:
\begin{equation}
\begin{matrix}
p_0(x)=P(x_0 \geq x) && , && \forall x\in \mathcal{X}
\end{matrix}
\nonumber
\end{equation}
\item $F$ is the stochastic clock structure and $F_e$ are the distributions of the lifetimes:
\begin{equation}
\begin{matrix}
F={F_e :e \in \mathcal{E}} && ; && F_e=P(V_{e,i} \leq t)
\end{matrix}
\nonumber
\end{equation}
\end{itemize}
\newpage
\paragraph{Exponential Distribution}
When computing probabilities (like the probability of reaching a given state within a certain amount of time), since the lifetimes are random variables, it’s normally possible to know only the distributions of the total lifetimes, but not the one of the ones of the residual lifetimes. An exception is the one of exponential distribution which has some helpful properties that we are going to observe. The exponential distribution is defined as follows:
\begin{equation}
\begin{matrix}
F_X(t)=P\left(X\leq t\right)=
\begin{cases}
1-e^{-\lambda t} & \textrm{if } t\geq 0 \\
0 & \textrm{otherwise} \\
\end{cases}
&&&
f_X(t)=\frac{dF_X(t)}{dt}=
\begin{cases}
\lambda e^{-\lambda t} & \textrm{if } t\geq 0 \\
0 & \textrm{otherwise} \\
\end{cases}
\end{matrix}
\end{equation}
Where $F_X(t)$ is the CDF and $f_X(t)$ is the PDF. The aforementioned properties are the following:
\begin{itemize}
\item \textbf{Memoryless property}: 
If the time between the occurrencies $X$ of a given event is modeled trough an exponential distribution and at the time $t$ the event hasn't occurred yet, the probability of the occurrence of the event (computed at a time $s>t$) does not depend $t$. In formulae:
\begin{equation}
P(X>t+s\hspace{4pt}|\hspace{4pt}X>t)=P(X>s)
\end{equation}
\emph{Proof:}
$$
P(X>t+s\hspace{4pt}|\hspace{4pt}X>t) = \frac{P(X>t+s \textrm{ , } X>t)}{P(X>t)} = \frac{P(X>t+s)}{P(X>t)} = 
\frac{1-P(X\leq t+s)}{1-P(X\leq t)} =
$$
$$
= \frac{1-F_X(t+s)}{1-F_X(t)} = \frac{e^{-\lambda (t+s)}}{e^{-\lambda t}} = e^{-\lambda s} =
1-P(X\leq s) = P(X>s)
$$
\begin{flushright}
$\blacksquare$
\end{flushright}
\item \textbf{Extended memoryless property}:
The memoryless property can be defined in a more generical way by considering, instead of the time $t$, a generic time distribution $Y$, with support in $\left[0,\infty \right)$, independent from $X$:
\begin{equation}
P(X>Y+s\hspace{4pt}|\hspace{4pt}X>Y)=P(X>s)
\end{equation}
\newpage
\emph{Proof:}
$$
P(X>Y+s\hspace{4pt}|\hspace{4pt}X>Y) = \frac{P(X>Y+s \textrm{ , } X>Y)}{P(X>Y)} = \frac{P(X>Y+s)}{P(X>Y)} 
$$
Let's focus on the numerator, the probability $P(X>Y+s)$ is equal to the marked area ($A$) in the following plot which is the area in which the value of $X$ is greater than $Y+s$.
\\\bigskip
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.5\textwidth]{IMG/CommArea.eps}
\caption{\small The highlighted area is the one for which $X-Y>s$}
\label{Picture 1}
\end{center}
\end{figure}
This consideration allows us to proceed as follows:
$$
P(X>Y+s) = P(X,Y\in A) = \int_{0}^{+\infty}dy\int_{y+s}^{+\infty}f_Y(y)\lambda e^{-\lambda x}dx=
$$
$$
=\int_{0}^{+\infty}f_Y(y)dy\int_{y+s}^{+\infty}\lambda e^{-\lambda x}dx=\int_{0}^{+\infty}f_Y(y)
\left[-e^{-\lambda x}\right]^{+\infty}_{y+s}dy =
$$
$$
=\int_{0}^{+\infty}f_Y(y)e^{-\lambda y}e^{-\lambda s}dy = e^{-\lambda s}
\int_{0}^{+\infty}f_Y(y)e^{-\lambda y}dy 
$$
Since the $s$ in the lower limit of integration in the innermost integral produces only a term 
$e^{-\lambda s}$ which can be put outside the integral, it's clear that the integral
$$
\int_{0}^{+\infty}f_Y(y)e^{-\lambda y}dy
$$
is equal to $P(X>Y)$. Thanks to this it's possible to solve the fraction to compute the probability 
$P(X>Y+s\hspace{4pt}|\hspace{4pt}X>Y)$:
$$
\frac{P(X>Y+s)}{P(X>Y)} = \frac{e^{-\lambda s}\int_{0}^{+\infty}f_Y(y)e^{-\lambda y}dy }
{\int_{0}^{+\infty}f_Y(y)e^{-\lambda y}dy } = e^{-\lambda s} = 1-P(X\leq s) = P(X>s)
$$
\begin{flushright}
$\blacksquare$
\end{flushright}
\newpage
\item \textbf{Superposition property}:
Let's consider the case in it's required to know, for independent events with exponentially distributed lifetimes $\left( X_i\sim Exp\left(\frac{1}{\lambda_i}\right)\right)$, the one that occurs first. The random variable that must be taken into account is:
$$
X=\min_{i=1,2,\dots,n}{\{X_i\}}
$$ 
The random variable $X$ is exponentially distributed with rate 
$$
\lambda '=\sum_{i=1}^{n}\lambda_i
$$
\emph{Proof:}
$$
P(X\leq t) = 1-P(X>t) = 1-P(\min_{i=1,\dots,n}{X_i}>t)
$$
From this last result, considering both the independence of the distributions and the fact that if the value $\min_i{\{X_i\}}$ is greater than $t$ then all the $X_i$ are, it's possible to proceed with the computation as follows:
$$
1-P(\min_{i=1,\dots,n}{X_i}>t) = 1-\prod_{i=1}^{n}{P(X_i>t)} = 1-\prod_{i=1}^{n}{1-P(X_i\leq t)} =
$$
$$
= 1-\prod_{i=1}^{n}{e^{-\lambda_{i}t}} = 1-e^{-\sum_{i}{\lambda_i t}} = 1-e^{-t\lambda'}
$$
Where $\lambda' = \sum_{i=1}{n}{\lambda_i}$.
\begin{flushright}
$\blacksquare$
\end{flushright}
\end{itemize}
In addition to these properties, a `useful computation' (for the next topics) will be executed. Given two exponentially distributed random variables $X\sim Exp\left(\frac{1}{\lambda}\right),Y\sim Exp\left(\frac{1}{\mu}\right)$, let's compute the probability $P(X \leq Y+s)$:
\\\bigskip
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.5\textwidth]{IMG/CommArea2.eps}
\caption{\small The highlighted area is the one for which $X-Y\leq s$}
\label{Picture 2}
\end{center}
\end{figure}
$$
P(X \leq Y+s) = \int_{0}^{+\infty}dy\int_{0}^{y+s}\lambda e^{-\lambda x}\mu e^{-\mu y}dx
= \int_{0}^{+\infty}\mu e^{-\mu y}dy\int_{0}^{y+s}\lambda e^{-\lambda x}dx = 
$$
$$
=\int_{0}^{+\infty}\mu e^{-\mu y}\left[ -e^{-\lambda x}\right]_0^{y+s}dy
= \int_{0}^{+\infty}\mu e^{-\mu y}\left[ 1-e^{-\lambda(y+s)}\right]dy =
$$
$$
= \int_{0}^{+\infty}\mu e^{-\mu y}dy - e^{-\lambda s}\int_{0}^{+\infty}\mu e^{-\mu y} e^{-\lambda y}dy
= \left[-e^{-\mu y} + \frac{\mu e^{-\lambda s}}{\lambda + \mu}e^{-(\lambda+\mu)y}\right]_{0}^{+\infty} =
$$
$$
= 1-\frac{\mu e^{-\lambda t}}{\lambda + \mu} \overset{\textrm{let's set }s=0}{\hspace{15pt}=\hspace{15pt}} 1-\frac{\mu}{\lambda + \mu} = \frac{\lambda}{\lambda + \mu} = P(X\leq Y) 
$$
In the next chapter this last result
\begin{equation}
P(X\leq Y)= \frac{\lambda}{\lambda + \mu}
\end{equation}
will be used a lot, so it's important to keep it in mind.
\section{Stochastic State Automata With Poisson Clock Structure}
\paragraph{Poisson Counting Processes} It's a process wich counts the occurrencies of an event which is always possible. In particular, in Poisson counting processes the `interarrival times' $T_i$ between any two occurrencies of the same event are \textit{i.i.d.} and have the same exponential distribution:
$$
T_i\sim Exp\left(\frac{1}{\lambda}\right),\hspace{20pt}t\geq 0,\hspace{20pt}\forall i
$$
\noindent
A Poisson counting process is defined as a discrete random variable $N_e(t,t+s)$ representing the number of occurrencies of the event $e$ in the interval $\left( t,t+s\right]$. In particular, given that the interarrival times are exponentially distributed, the PMF of the Poisson counting process is:

\begin{equation}
P\left(N_e(t,t+s)\right)\hspace{15pt}\underset{\textrm{exponential distribution}}
{\overset{\textrm{memoryless property of}}{=}}\hspace{15pt}P\left(N_e(s)\right)\hspace{10pt}=
\hspace{10pt}\frac{(\lambda s)^n}{n!}e^{-\lambda s}
\end{equation}

\noindent
From the PMF definition we can also reach the following result. Given $n$ \textit{i.i.d.} interarrival times $T_1,T_2,\dots,T_n \sim Exp\left(\frac{1}{\lambda}\right)$, $\lambda>0$:
$$
P\left(T_1,T_2,\dots,T_n \leq s\right) = 1-\sum_{m=0}^{n-1}P(N_e(s)=m)=1-\sum_{m=0}^{n-1}
\frac{(\lambda s)^m}{m!}e^{-\lambda s}
$$
Given by the fact that, for the sum of the $n$ interarrival times to be less than $s$, the number of events occurred in the time $s$ has to be at least $n$.
\newpage
\paragraph{Stochastic Timed Automaton With Poisson Clock Structure}
It's a stochastic timed automaton 
$(\mathcal{E},\mathcal{X},\Gamma,P,p_0,F)$ where $F={F_e : e\in \mathcal{E}}$, \textbf{with \textit{i.i.d.} events' lifetimes} and:
$$
F_e(t)=1-e^{-\lambda_e t},\hspace{20pt}t\geq 0,\hspace{20pt}\lambda_e>0
$$
It's important to notice that there is no constraint about wether the events are always possible or not, this means that the `Poisson clock structure' doesn't refer to a Poisson counting process but to the fact that all the events have exponential interarrival times.
\emph{Moreover, for stochastic timed automata with Poisson clock structure, the residual lifetimes of the events follow the same distribution of the corresponding total lifetime}. This last porperty can be proved through induction. The actual demonstration can be considered as homework by the reader.

\bigskip
\noindent
In stochastic timed automata with Poisson clock structure it's quite easy (compared to other models) to compute useful probabilities, such as:
\begin{itemize}
\item $P(E_{k+1}=e\hspace{4pt}|\hspace{4pt}X_k=x)$, which is the probability that the next event $E_{k+1}$ (uppercase, since it's a random variable) will be $e$, given that the current state is $x$:
$$
P(E_{k+1}=e\hspace{4pt}|\hspace{4pt}X_k=x)=P\left(Y_{e,k}< \min_{\small\left[
\begin{matrix}
e'\in \Gamma(x) \cr
e'\neq e
\end{matrix}\right]
}{\left\lbrace Y_{e',k}\right\rbrace }\right)
$$
Were the $Y$ random variables are the residual lifetimes of the consideed events. Since in this case the residual lifetimes follow exponential distribution, it's possible to use the equation $(4)$ to proceed with the computation:
\begin{equation}
=P\left(Y_{e,k}< \min_{\small\left[
\begin{matrix}
e'\in \Gamma(x) \cr
e'\neq e
\end{matrix}\right]
}{\left\lbrace Y_{e',k}\right\rbrace }\right)
=\frac{\lambda_e}{\lambda_e+\left[\Lambda(x)-\lambda_e\right]}=\frac{\lambda_e}{\Lambda(x)}
\end{equation}

\noindent
Where $\Lambda(x)$ comes from $\min_{e'}{\left\lbrace Y_{e',k}\right\rbrace } \sim Exp\left(\frac{1}
{\sum{\lambda_e'}}\right)$. $\Lambda(x)$ was insterted in order to ease the computation and it's defined as:
$$
\Lambda(x)=\sum_{e \in \Gamma (x)}{\lambda_e}
$$
So, by defining $\Lambda(x)$ as the sum of the rates of all the possible events, it's possible to obtain:
$$
\min_{\small\left[
\begin{matrix}
e'\in \Gamma(x) \cr
e'\neq e
\end{matrix}\right]
}{\left\lbrace Y_{e',k}\right\rbrace }) \sim Exp\left(\frac{1}{\underset{{\small\left[
\begin{matrix}
e'\in \Gamma(x) \cr
e'\neq e
\end{matrix}\right]
}}{\sum
}\lambda_e'}\right)
\triangleq
Exp \left(\frac{1}{\Lambda(x)-\lambda_e}\right)
$$
Which is the passage that makes possible to reach the last result of $(6)$.
\newpage
\item $P(X_{k+1}=x'\hspace{4pt}|\hspace{4pt}X_k=x)$ , which is the probability that the next state is $x'$, givent that the current state is $x$:
$$
P(X_{k+1}=x'\hspace{4pt}|\hspace{4pt}X_k=x) \hspace{20pt}\underset{\textrm{rule}}{\overset{\textrm{total probability}}{=}}
$$
$$
=\sum_{e\in \Gamma(x)}{
\left[
P\left(
X_{k+1}=x'\hspace{4pt}|\hspace{4pt}X_k=x\textrm{, }E_{k+1}=e
\right)\cdot
P\left(
E_{k+1}=e\hspace{4pt}|\hspace{4pt}X_k=x
\right)
\right]
}=
$$
$$
=
\sum_{e\in \Gamma(x)}{
\left[
P\left(
X_{k+1}=x'\hspace{4pt}|\hspace{4pt}X_k=x\textrm{, }E_{k+1}=e
\right)\cdot
\frac{\lambda_e}{\Lambda(x)}
\right]}\triangleq
$$
$$
\underset{\textrm{for a more lean notation}}{\triangleq}
\sum_{e\in \Gamma(x)}{
\left[
P\left(x'\hspace{4pt}|\hspace{4pt}x,e
\right)\cdot
\frac{\lambda_e}{\Lambda(x)}
\right]}
$$
\end{itemize}
These two results are quite good, but there are still more things that can be done. By defining 
$\mathcal{E}=\left\lbrace 1,2,\dots,m \right\rbrace$ and 
$\mathcal{X}=\left\lbrace 1,2,\dots,n \right\rbrace$
it's possible to define the following matrices and vector:

\bigskip
$$
P_E=
\left[
\begin{matrix}
P\left(E_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=1\right)&&
P\left(E_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=1\right)&&
\dots&&
P\left(E_{k+1}=m \hspace{4pt}|\hspace{4pt} X_k=1\right)\cr\cr
P\left(E_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=2\right)&&
P\left(E_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=2\right)&&
\dots&&
P\left(E_{k+1}=m \hspace{4pt}|\hspace{4pt} X_k=2\right)\cr\cr
\vdots&&
\vdots&&
\ddots&&
\vdots\cr\cr
P\left(E_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=n\right)&&
P\left(E_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=n\right)&&
\dots&&
P\left(E_{k+1}=m \hspace{4pt}|\hspace{4pt} X_k=n\right)
\end{matrix}
\right]
$$

\bigskip
$$
P_X=
\left[
\begin{matrix}
P\left(X_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=1\right)&&
P\left(X_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=1\right)&&
\dots&&
P\left(X_{k+1}=n \hspace{4pt}|\hspace{4pt} X_k=1\right)\cr\cr
P\left(X_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=2\right)&&
P\left(X_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=2\right)&&
\dots&&
P\left(X_{k+1}=n \hspace{4pt}|\hspace{4pt} X_k=2\right)\cr\cr
\vdots&&
\vdots&&
\ddots&&
\vdots\cr\cr
P\left(X_{k+1}=1 \hspace{4pt}|\hspace{4pt} X_k=n\right)&&
P\left(X_{k+1}=2 \hspace{4pt}|\hspace{4pt} X_k=n\right)&&
\dots&&
P\left(X_{k+1}=n \hspace{4pt}|\hspace{4pt} X_k=n\right)
\end{matrix}
\right]
$$

\bigskip
$$
\Pi_X(k)=
\left[
\begin{matrix}
P(X_k=1)&
P(X_k=2)&
\cdots&
P(X_k=n)&
\end{matrix}
\right]
$$

\bigskip
\noindent
So it's possible to define the probability that the $k+1-th$ state is $j$ as:
$$
P\left(X_{k+1}=j\right)=\sum_{i\in \mathcal{X}}{
\underbrace{P\left(X_{k+1}=j \hspace{4pt}|\hspace{4pt} X_k=i\right)}_{(i,j)-th\text{ entry of }P_X}
\underbrace{P\left(X_k=1\right)}_{i-th\text{ entry of }\Pi_X(k)}
}
$$ 
which will be the $j-th$ entry of the vector $\Pi_X(k+1)$. 
\newpage
\noindent
So assuming that $\Pi_X(0)$ is known:
$$
\Pi_X(0)=
\left[
\begin{matrix}
P_0(1),&
P_0(2),&
\cdots,&
P_0(n)
\end{matrix}
\right]
$$
$$
\begin{matrix}
\Pi_X(1)&=&\Pi_X(0)P_X\cr
\Pi_X(2)&=&\Pi_X(1)P_X&=&\Pi_X(0)P_X\cr
\Pi_X(3)&=&\Pi_X(2)P_X&=&\Pi_X(0)P_X^2\cr
&&\vdots\cr
\Pi_X(k)&=&\Pi_X(0)P_X^k
\end{matrix}
$$

\bigskip
\noindent
Likewise, it's possible to obtain the same result for the events: 
$$
P\left(E_{k+1}=e\right)=\sum_{x\in\mathcal{X}}{P\left(E_{k+1}=e\hspace{4pt}|\hspace{4pt}X_k=x\right)P\left(X_k=x\right)}
$$

$$
\Pi_E(k)=
\left[
\begin{matrix}
P\left(E_K=1\right),&
P\left(E_K=2\right),&
\cdots,&
P\left(E_K=m\right)
\end{matrix}
\right]
$$

$$
\Pi_E(k+1)=\Pi_X(k)P_E=\Pi_X(0)P_X^kP_E
$$
With this result, it's finally possible to say that \emph{when using stochastich timed automata with Poisson clock structure, it's enough to know the matrices $P_X$ and $P_E$ and the vector $\Pi_X(0)$ to find all the future state and event probabilities}. 
\paragraph{Distribution of State Holding Times} Let's consider the state $x$ of a stochastic rimed automaton with Poisson clock structure. The state holding time $V(x)$ is defined as the time spent by the system in the state $x$, so $V(x)$ is a continuous random variable. Moreover, when computing a state holding time, it's fundamental to keep in mind the fact that, while the system is in state $x$, events can occur without causing a state transition and, therefore, without affecting the value of $V(x)$.

\bigskip
\noindent
\textbf{Theorem}: 

\noindent
The State holding time $V(x)$ of the state $x$, in stochastic timed automata with Poisson clock structure, is exponentially distributed with rate:

$$
\sum_{e\in\Gamma(x)}{\lambda_e
\left[
1-P\left(x\hspace{4pt}|\hspace{4pt}x,e\right)
\right]
}
$$
\newpage
\noindent
\emph{Proof:}

\bigskip
\noindent
Let's start with the computation of the CDF of $V(x)$:
$$
P(V(x)\leq t) = 1-P(V(x)> t)
$$
Now let's consider only the term $P(V(x)> t)$:
$$
P(V(x)> t)=P\left(\textrm{\emph{ no state transitions in the time interval }}\left( 0,t\right]\hspace{4pt}|\hspace{4pt}X(0)=x\right)=
$$
$$
=P\left(\underset{e\in\Gamma(x)}{\bigcap}\textrm{\emph{ no state transition triggered by event }}e
\textrm{\emph{ in the time interval }}\left( 0,t\right]\hspace{3pt}|\hspace{3pt}X(0)=x\right)=
\footnote[1]{Thanks to the independence of the events' lifetimes in Poisson clock structure}
$$
$$
=\prod_{e\in\Gamma(x)}{
P\left(\textrm{\emph{ no state transition triggered by event }}e\textrm{\emph{ in the time interval }}
\left( 0,t\right]\hspace{4pt}|\hspace{4pt}X(0)=x\right)
}=
$$
$$
=\prod_{e\in\Gamma(x)}{
P\left(
\begin{matrix}
\underset{n=0}{\overset{+\infty}{\bigcup}}
\textrm{\emph{ event }}e\textrm{\emph{ occurs exactly }n\textrm{\emph{ times in }}}
\left( 0,t\right]\textrm{\emph{ and}}\cr
\textrm{\emph{ never triggers a state transition }} \hspace{4pt}|\hspace{4pt}X(0)=x
\end{matrix}
\right)\overset{\textrm{union of}}{\underset{\textrm{disjoint events}}{=}}
}
$$
$$
=\prod_{e\in\Gamma(x)}{\sum_{n=0}^{+\infty}{
P\left(
\begin{matrix}
\textrm{\emph{ event }}e\textrm{\emph{ occurs exactly }}n\textrm{\emph{ times in the interval }}\left( 0,t\right]\cr
\textrm{\emph{ and never triggers a state transition }} \hspace{4pt}|\hspace{4pt}X(0)=x
\end{matrix}
\right)}}=
$$

\bigskip\noindent
In this last probability the occurrencies of an \textit{i.i.d} set of esponentially distributed random variables are counted, which is equivalet to a Poisson counting process. Therefore, it's possible to use the equation $(5)$ 

\begin{Large}
$$
=\prod_{e\in\Gamma(x)}{\sum_{n=0}^{+\infty}{
\frac{\left(\lambda_e t\right)^{n}}{n!} e^{-\lambda_e t} P\left( x\hspace{4pt}|\hspace{4pt}x,e\right)^{n}}}
=\prod_{e\in\Gamma(x)}{e^{-\lambda_e t}\sum_{n=0}^{+\infty}{
\frac{\left[\lambda_e t\cdot P\left(x\hspace{4pt}|\hspace{4pt}x,e\right)\right]^n}{n!}
}}=
$$
\end{Large}

\medskip
\noindent
The sum corresponds to the definition of the exponential: $e^x=\sum_{n=0}^{+\infty}{\frac{x^n}{n!}}$

\begin{Large}
$$
=\prod_{e\in\Gamma(x)}{e^{-\lambda_e t}
e^{\left[\lambda_e t\left(P\left(x\hspace{4pt}|\hspace{4pt}x,e\right)e\right)\right]}
}
=e^{\sum_{e\in\Gamma(x)}{\left(-\lambda_e
\left[
1-P\left(x\hspace{4pt}|\hspace{4pt}x,e\right)
\right]t\right)
}}
$$
\end{Large}

\medskip\noindent
So, finally we can obtain:
\begin{Large}
$$
P\left(V(x)\leq t\right)=1-
e^{\sum_{e\in\Gamma(x)}{\left(-\lambda_e
\left[
1-P\left(x\hspace{4pt}|\hspace{4pt}x,e\right)
\right]t\right)
}}
$$
\end{Large}
\begin{flushright}
$\blacksquare$
\end{flushright}
\newpage
\section{Markov Chains}
\paragraph{Stochastic Processes}
An example of a stochastic process was already proposed when talking about `Poisson counting process', now a slightly more formal definition will be given: \emph{`a stochastic process is a collection $\left\lbrace X\left(t\right) \right\rbrace_{t\in T} $
of random variables indexed by a time index $t\in T$'}, where $T$ is a time interval which can be either discrete or continuous.
The stocastic processes are actually classified depending on the nature of $T$:
\begin{itemize}
\item \textbf{if $T$ is discrete} the process is a \emph{`discrete time stochastic process'} 
and it's also called \emph{`chain'}.
\item \textbf{if $T$ is continuous} the process is a \emph{`continuous time stochastic process'}.
\end{itemize}
To caracterise stochastic processes it's necessary to provide joint distributions of all the possible $n-tuples$ of the random variables which compose the process. Since this is really hard to realise, in these notes the stochastic processes will be used
only when the independence between the random variables holds, therefore with stochastic timed automata with Poisson clock structure. Finally, the independence concept in stochastic processes is defined as follows:

\bigskip
\noindent 
Given $X(t_1), X(t_2),\dots, X(t_n)$ $n-tuples$ of random variables with $t_1<t_2<\dots<t_n \in T$ and $n=2,3,4,\dots$ the process is said \emph{`independent'} only if all the $n-tuples$ are independent. 

\bigskip
\noindent 
Let $x(t)$ be the realisation of the random variable $X(t)$, if the condition:
$$
P\left(X\left(t+s\right)=\overset{\sim}{x}\hspace{4pt}|\hspace{4pt}X\left(\tau\right)=
x\left(\tau\right),\hspace{5pt}\forall\tau\leq t\right)=
P\left(X\left(t+s\right)=\overset{\sim}{x} \right)
$$
holds, the process is independent.
\paragraph{Continuous Time Homogeneous Markov Chains (CTHMC)} are a subset of a kind of stochastic processes called `Markov processes' for which the definition of process independence is more relaxed than the standard one just given. If the condition:
$$
P\left(X\left(t+s\right)=\overset{\sim}{x}\hspace{4pt}|\hspace{4pt}X\left(\tau\right)=
x\left(\tau\right),\hspace{5pt}\forall\tau\leq t\right)=
P\left(X\left(t+s\right)=\overset{\sim}{x} \hspace{4pt}|\hspace{4pt} X\left(t\right)=x\left(t\right)\right)
$$
holds, the process is independent. This definition allows the stochastic processes whose next realisation depends only on the current one to be called independent (\emph{`Markov property'}).

\bigskip
\noindent
The Continuous Time Homogeneous Markov Chains are stochastic processes with the following properties:
\begin{itemize}
\item $T=\mathbb{R}^+\Rightarrow\left\lbrace t\in\mathbb{R};\hspace{3pt}t\geq 0\right\rbrace $ (\textbf{Continuous Time}).
\item $x(t)\in \mathcal{X}=\left\lbrace 1,2,\dots\right\rbrace$ (\textbf{Chain}).
\item \textbf{Markov property}.
\item \textbf{Homogeneity}: 
$$
P\left(x\left(t+s\right)=j\hspace{4pt}|\hspace{4pt}x\left(t\right)=i\right)
\hspace{5pt}=\hspace{5pt}
P\left(x\left(t'+s\right)=j\hspace{4pt}|\hspace{4pt}x\left(t'\right)=i\right),\hspace{5pt}\forall t\neq t'
$$
\end{itemize} 
\paragraph{Chapman-Kolmogorov Equation}
Please notice that $x(t)\in \mathcal{X}$ implies that the process' random variables realisations are the states of the system modeled as a CTHMC. So, let's try to compute the probability that, given a current state $i$, after a time $s$ the state will be $j$:
$$
P_{i,j}(s)=P\left(X\left(t+s\right)\hspace{4pt}|\hspace{4pt} X\left(t\right)=i\right)
$$
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.35\textwidth]{IMG/CTHMC1.eps}
\label{Picture 3}
\end{center}
\end{figure}
\noindent
In order to execute the computation, let's consider the case in the figure above:
$$
P_{i,j}(s)=P\left(X\left(t+s\right)=j\hspace{4pt}|\hspace{4pt} X\left(t\right)=i\right)=
$$
$$
=\sum_{r\in \mathcal{X}}{
P\left(X\left(t+s\right)=j\hspace{4pt}|\hspace{4pt} X\left(t+u\right)=r,\hspace{5pt} X\left(t\right)=i\right)
}\cdot 
P\left(X\left(t+u\right)=r\hspace{4pt}|\hspace{4pt}X\left(t\right)=i\right)
\hspace{5pt}\overset{Markov}{\underset{property}{=}}
$$
$$
=\sum_{r\in \mathcal{X}}{
P\left(X\left(t+s\right)=j\hspace{4pt}|\hspace{4pt} X\left(t+u\right)=r\right)
P\left(X\left(t+u\right)=r\hspace{4pt}|\hspace{4pt} X\left(t+u\right)=i\right)
}=
$$
$$
=\sum_{r\in \mathcal{X}}{
P_{i,r}\left(u\right)
P_{r,j}\left(s-u\right)
}
$$
The result of the computation:
\begin{equation}
P_{i,j}(s)
=\sum_{r\in \mathcal{X}}{
P_{i,r}\left(u\right)
P_{r,j}\left(s-u\right)
}
\end{equation}
is known as `Chapman-Kolmogorov equation'. As seen for the stochastic timed automata with Poisson clock structure, also here it's possible to define a matrix collecting all the probabilities of the kind $P_{i,j}(s)$. Let's call this matrix $H(s)$:

\bigskip\noindent
$$
H(s)=\left[
\begin{matrix}
P_{1,1}(s)&P_{1,2}(s)&\cdots\cr
P_{2,1}(s)&P_{2,2}(s)&\cdots\cr
\vdots&\vdots&\ddots
\end{matrix}
\right]
$$

\bigskip\noindent
This matrix has some important properties:
\begin{enumerate}
\item Since all the elements of the $H(s)$ are probabilities, the matrix tis structured in such a way that the sum of all the elements in a row is alway $1$.
\item As a result of the previous property, the probability that after a time $s=0$ the state hasn't chenged is $1$, therefore:
$$
H(0)=I
$$
\item Since for the Chapman-Kolmogorov equation $(7)$ refers to $P_{i,j}(s)$ which is the generic element of the matrix $H(s)$, it's possible to define the equation $(7)$ also for the matrix:
$$
H(s)=H(u)H(s-u)
$$
\newpage
\item From the last property it's possible to find the derivative of $H(s)$:
$$
\frac{dH(s)}{ds}=H(s)Q\hspace{10pt},\hspace{10pt}Q\triangleq\lim_{ds\rightarrow 0}\frac{H(ds)-I}{ds}
$$

\noindent
\emph{Proof}:

$$
H(s+ds)=H(s)H(ds)\hspace{10pt}\overset{\textrm{subtracting both the sides for}}
{\underset{H(s) \textrm{ and dividing them for }ds}{\Rightarrow}}
$$

\medskip
$$
\Rightarrow
\frac{H(s+ds)-H(s)}{ds}=\frac{H(s)H(ds)-H(s)}{ds}
$$

\medskip
Taking the limit for $ds\rightarrow 0$ of both the sides of the equation:

$$
\lim_{ds\rightarrow 0}{\frac{H(s+ds)+H(s)}{ds}}=
\lim_{ds\rightarrow 0}{\frac{H(s)+H(ds)}{ds}} \Rightarrow
$$

\medskip
$$
\Rightarrow
\frac{dH(s)}{ds}=H(s)\lim_{ds\rightarrow 0}{\frac{H(ds)-I}{ds}}
$$

\medskip
The rightside limit has an indeterminate form. Let's assume that the limit exists and let's call it $Q$. Since the all the elements involved in the limit are matrices, also $Q$ will be a matrix. Considering also property $\#2$ it's possible to write the following Cauchy problem:

\begin{Large}
$$
\begin{matrix}
\begin{cases}
\frac{dH(s)}{ds}=H(s)Q\\
H(0)=I \\
\end{cases}
\end{matrix}
$$
\end{Large}

\noindent 
Whose solution is:
$$
H(s)=e^{Qs}\hspace{10pt},\hspace{10pt}e^{Qs}=\sum_{n=0}^{+\infty}{\frac{\left( Qs\right)^n}{n!}}
$$ 
Where $e^{Qs}$ is a matrix exponential. Finally it's also possible to check if $Q$ actually exists:
$$
\lim_{ds\rightarrow 0}{\frac{H(ds)-I}{ds}}\hspace{10pt}=
\hspace{10pt}\lim_{ds\rightarrow 0}{\frac{e^{Qds}-I}{ds}}
\hspace{10pt}
\overset{\textrm{Taylor}}{\underset{1^{st}\textrm{ order}}{=}}
\hspace{10pt}
\lim_{ds\rightarrow 0}{\frac{(I+Qds+o(ds))-I}{ds}}\hspace{10pt}=
$$

\medskip
$$
=\lim_{ds\rightarrow 0}{\frac{Qds}{ds}+\frac{o(ds)}{ds}}=Q
$$

\medskip
Which means that the result is consistent with the soultion found by solving the Cauchy problem.
\hspace{373pt}$\blacksquare$
\end{enumerate}
\emph{It's important to keep in mind that $Q$ has, as a property $(\star)$, that the sum of all the elements in a row is zero, for every row. This implies that one
\footnote[2]{Only one eigenvalue is zero, in fact the property ($\star$) implies the linear dependency of one of the columns, so $rank(Q)=dim(Q)-1$. Since the $\#$ of eigenvalues in zero is equal to $dim(Q)-rank(Q)$, in this case there's $1$. } 
of its eigenvalues ($\lambda$) is equal to $0$.}
\newpage
\subsection{Steady State Analysis}
Formally the matrix $Q$ is called `\emph{transition rate matrix}' and through this it's possible to determine, for each state, the probability that the system is exactly in that state at time $t$.
Let's consider the `State Probability Vector' $\Pi(t)$, similar to the one in `\emph{Section $4$}':
$$
\Pi(t)\triangleq \left[
\begin{matrix}
&\Pi_1(t),& \Pi_2(t),& \Pi_3(t),& \dots&
\end{matrix}
\right]
$$ 
The `State Probability' of the generic $j-th$ state will be obtained as:

$$
\Pi_j\left(t\right)\hspace{5pt}=\hspace{5pt} P\left(x\left(t\right)=j\right)
\hspace{5pt}=\hspace{5pt} 
\sum_{i\in\mathcal{X}}{
\underbrace{
P\left( x \left( t \right) = j \hspace{4pt}|\hspace{4pt}  x\left(0\right)=i\right)
}_{P_{i,j}(t)}
\cdot
\underbrace{
P\left(x\left(0\right)=i\right)
}_{\Pi_i(0)}
}\hspace{5pt}=\hspace{5pt}
\Pi(0)\cdot H_j(t)
$$

\noindent
Where $H_j(t)$ is the $j-th$ column of the matrix $H(t)$. This means that it's possible to compute all the state probabilities in one go by using:
\begin{equation}
\Pi(t)\hspace{5pt}=\hspace{5pt}
\Pi(0)\cdot H(t)\hspace{5pt}=\hspace{5pt}
\Pi(0)\cdot e^{Qt}
\end{equation}
In the kind of system treated in this section the behaviour of the probabilities in time can be divided in two states: `Transient State' and `Steady State':
\begin{itemize}
\item \textbf{Transient State}: In order to analyse the behaviour of the system's state probabilities during the transient state, the derivative of $\Pi(t)$ must be computed:

$$
\frac{d\Pi(t)}{dt}
\hspace{5pt}=\hspace{5pt}
\Pi(0)\frac{dH(t)}{dt}
\hspace{5pt}=\hspace{5pt}
\Pi(0)H(t)Q
\hspace{5pt}=\hspace{5pt}
\Pi(t)Q
$$

\noindent
Which means that, to study the behaviour of the system in the transient state, it's enough to find the solution to the following Cauchy problem:

\begin{Large}
$$
\begin{matrix}
\begin{cases}
\frac{d\Pi(t)}{dt}=\Pi(t)Q\\
\Pi(0)=\Pi_0 \\
\end{cases}
\end{matrix}
$$
\end{Large}

\noindent
Where $\Pi_0$ is the initial state of the system.
\item \textbf{Steady State}: A system reaches steady state when every probability in the system starts varying less and instead converges asymptotically to a constant value. So in order to study steady state probabilities, it's necessary to focus on the following limit:

$$
\lim_{t\rightarrow \infty}{\Pi_i(t)}
$$
\end{itemize}
\newpage
\paragraph{Classification of States} in this paragraph some properties of the states, useful for the steady state analysis, will be explained:
\begin{itemize}
\item \textbf{Reachability}: A generic state $j$ is reachable from state $i$ if
$$
\exists\hspace{3pt}s : P_{i,j}(s)>0.
$$
Such concept can be also informally explained with the following definition: `\emph{it must exist a directed path from state $i$ to state $j$}'.
\item \textbf{Closure}: A subset $S\subseteq\mathcal{X}$ is `\emph{closed}' if 
$$
P_{i,j}=0,\hspace{10pt} \forall i\in S,\hspace{10pt} j\in\mathcal{X} \setminus S.
$$
Infomally, it's possible to say that from the subset $S$ it's not possible to reach the states of the subset $\mathcal{X}\setminus S$:
\begin{figure}[H]
\begin{center}
$$
\begin{tikzpicture}
[
   thick,
   align=center,
   every state/.style={draw=black!60, fill=black!5}
]

\tikzset{state/.style = {shape=ellipse,draw, node distance=2cm}}
\tikzset{edge/.style = {->,> = angle 60, thick}}
% nodes
\node[state] (a) at  (0,0) {$1$};
\node[state,draw=none] (s) [left = 0.5cm of a] {};
\node[state] (b) [below =2cm of a] {$2$};
\node[state] (c) [right =2cm of a] {$3$};
\node[state] (d) [below =2cm of c] {$4$};
% arcs

\path[->]
   (s) edge  node[auto] {} (a)
   (a) edge node[auto] {} (b)
   (b) edge[bend left]  node[auto] {} (a)
   (a) edge node[auto] {} (c)
   (c) edge[bend left]  node[auto] {} (d)
   (d) edge node[auto] {} (c)
   (b) edge node[auto] {} (c)
   
;
\end{tikzpicture}
$$
\captionsetup{margin={60pt,60pt}}
\caption{\small the subset $\{3,4\}$ is an example of closed set, since once the system enters in state $3$ it's not possible that it will return to state $1$ or $2$ anymore.}
\end{center}
\end{figure}
\item \textbf{Irreducibility}: A closed subset $S\subseteq\mathcal{X}$ is called irreducible if every state of $S$ is reachable from other states of $S$.
\item \textbf{Recurrence}: Let's define the random variable $T_{i,i}$ as the time that takes to the system to return in state $i$. Let's also define the probability 
$\rho_i(t) \triangleq P\left( T_{i,i}<t\right)
$. By considering the limit for $t\rightarrow\infty$ of $\rho_i(t)$ it's possible to know wether the system will ever return to state $i$.

$$
\rho_i\triangleq\lim_{t\rightarrow\infty}{\rho_i(t)}=
\begin{matrix}
\begin{cases}
1 & \textrm{ then the state will return (for }t\rightarrow\infty\textrm{) to the state i}\\
a<1 & \textrm{ then the state i is transient}\\
\end{cases}
\end{matrix}
$$

\noindent
Starting form the assumption that the state $i$ is recurrent, it's possible to realise a further classification. First of all it's important to remember that $\rho_i(t)$ is the CDF of $T_{i,i}$, so it's possible to define also the PDF $f_i(t)$ as $\rho_i(t)$'s derivative.
\newpage
So, now it's possible to compute the expected value $M_i$ of $T_{i,i}$, as follows:
$$
M_i\triangleq E\left[T_{i,i}\right]=\int_{0}^{+\infty}{t\cdot f_i(t)dt}=
\begin{matrix}
\begin{cases}
\infty & \textrm{then the integral doesn't converge and }\\
&\textrm{the state }i\textrm{ it's called `null recurrent'.}\\
a<\infty & \textrm{then the integral converges and }\\
& \textrm{the state }i\textrm{ it's called `positive recurrent'.}\\
\end{cases}
\end{matrix}
$$
In real applications the behaviours of null recurrent and transient states are the same, so the positive recurrent states are the only ones in which the system actually returns to the state $i$.
\end{itemize} 
From these definition it's possible to define two theoremes and an important corollary:
\begin{enumerate}
\item If $i$ is a positive recurrent state and $j$ is reachable from $i$, then $j$ is positive recurrent.
\item If $S$ is a closed, irreducible and finite subset of $\mathcal{X}$, then all the states in $S$ are positive recurrent.
\item [2.1.] \underline{\emph{An irreducible and finite Markov Chain has only positive recurrent states.}}
\end{enumerate}
\paragraph{Steady State Analysis}
Let's now define the stationary probability vector:
$$
\Pi\triangleq \left[
\begin{matrix}
&\Pi_1,& \Pi_2,& \Pi_3,& \dots&
\end{matrix}
\right]
\hspace{10pt},\hspace{10pt}
\Pi_i\triangleq
\lim_{t\rightarrow\infty}{\Pi_i(t)}
$$ 
The actual definition of the stationary probability vector brings some problems that need to be solved before actually working with it, such as:
\begin{itemize}
\item Existence of the limit.
\item Conditions for the independence from the initial state $\Pi_0$.
\item Consistency of the probability vector, as the limit might exist but the probabilities might not sum up to $1$. 
\end{itemize}
A theorem (whose proof is not provided in these notes) states that for Continuous Time Homogeneous Markov Chains these problems, under precise conditions, can be all easily solved.

\bigskip
\noindent
\textbf{Theorem}: 

\noindent
For a CTHMC, which is irreducible and with all positive recurrent states, the limits
$$
\Pi_i=
\lim_{t\rightarrow\infty}{\Pi_i(t)}
$$
exist, with $\Pi_i>0,\hspace{4pt}\forall i\in\mathcal{X}$ and they are all independent of $\Pi_0$. Moreover, the vector $\Pi$ can be computed by solving the system of linear equations:

\begin{large}
$$
\begin{matrix}
\begin{cases}
\Pi Q=0\\
\underset{i\in\mathcal{X}}{\sum{}}{\Pi_i=1}
\end{cases}
\end{matrix}
$$
\end{large}
\newpage
\noindent
From this last theorem, keeping in mind also the corollary $\#2.1$ of the previous paragraph, the following corollary can be obtained:

\bigskip
\noindent
\textbf{Corollary}: 

\noindent
The previous theorem holds for irreducible and finite CTHMC.

\bigskip
\noindent
In both the theorem an the corollary the vector $\Pi$ can be found by solving the following system:
$$
\begin{matrix}
\begin{cases}
\Pi Q=0 & n \textrm{ equations}\\
\underset{i\in\mathcal{X}}{\sum{}}{\Pi_i=1} & 1 \textrm{ equation}
\end{cases}
\end{matrix}
$$
Where $n$ is the cardinality of $\Pi$. This means that there is a redundant equation, which can be found in $\Pi Q=0$, due to the fact that $Q$ doesn't have full rank since it has an eigenvalue $\lambda =0$. So, the constraint $\sum_{i\in\mathcal{X}}{\Pi_i=1}$ ensures both the consistency of the probability vector and the existance of a unique solution.

\noindent
As a final clarification about the equations in the system, the set of equations given by $\Pi Q=0$ comes from the definition already treated for the transient state definition:
$$
\frac{d\Pi(t)}{dt}=\Pi(t)Q
$$ 
Since for $t\rightarrow\infty$ the state probabilities are expected to converge to constant values, their derivatives are expected to converge to zero, so:
$$
\frac{d\Pi(t)}{dt}=\Pi(t)Q \hspace{10pt} \overset{t\rightarrow\infty}{\Rightarrow}\hspace{10pt} \Pi Q=0
$$
\paragraph{Equivalent CTHMC for Stochastic Timed Automata With Poisson Clock Structure}

\noindent A Stochastic Timed Automaton with Poisson Clock Structure $(\mathcal{E},\mathcal{X},\Gamma,P,p_0,F)$
is `stocastically equivalent' to a CTHMC $(\mathcal{X},Q,\Pi_0)$ which has:
\begin{itemize}
\item the same ditributions for the state holding times:
$$
V_i \sim Exp\left(\frac{1}{-q_{i,i}}\right)
$$
\item the same state transition probabilities:
$$
p_{i,j}=\frac{q_{i,j}}{-q_{i,i}}
$$
\end{itemize}  
Where $p_{i,j}$ is the generic element of the matrix $P_X$ of the Stochastic Timed Automaton with Poisson CLock Structure
and $q_{i,j}$ is the generic element of the matrix $Q$ of the CTHMC. 
\newpage
\end{document}
